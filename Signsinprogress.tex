	\documentclass[twoside]{article}
\usepackage{estilo-ejercicios}
\setcounter{section}{0}
\newtheorem{defin}{Definition}[section]
\newtheorem{lem}[defin]{Lemma}
\newtheorem{propo}[defin]{Proposition}
\newtheorem{thm}[defin]{Theorem}
\newtheorem{eje}[defin]{Example}
\newtheorem{obs}[defin]{Observación}
\renewcommand{\baselinestretch}{1,3}

\usepackage{empheq}
\newcommand*\widefbox[1]{\fbox{\hspace{2em}#1\hspace{2em}}}
%--------------------------------------------------------
\begin{document}

\title{ signs}
\author{Javier Aguilar Martín}
\maketitle

%\varprojlim
%\varinjlim

\section{Signs to try}
\begin{itemize}
\item No signs: this does not satisfy the defining equation of brace algebra since no sign at all would appear ACTUALLY THE KOSZUL RULE WHEN APPLYING THE MAP SHOULD GIVE THE SIGN IN THE BRACE RELATION, CHECK IT, THE PROBLEM WITH THIS IS THAT IT DOESN'T GIVE THE SIGNS THAT WE WANT IN $A_\infty$-ALGEBRAS 
To do that, when computing $x\{y_1,\dots, y_n\}\{z_1,\dots, z_m\}$, fix the number of $z$'s inserted in front of $y_1$, which gives the first koszul sign. For each of this amounts, fix the number of $z$'s inserted inside $y_1$. Each of this inserstions produces a bracket $y_1\{\cdots\}$. For each of these options, fix then the amount of $z$'s between $y_1$ and $y_2$ and so on. TRY TO USE THIS STRATEGY FOR OTHER SIGNS
\item With the notation of the draft of the derived Deligne conjecture, and $N=k_0+\cdots+k_n+n$, $g_0=f$:
\[
\varepsilon=\sum_{j<i}(a_i-1)(k_j+a_j-1)+\sum_{1\leq i}(N-i)q_i+\sum_{i\leq j<i}q_ia_j
\]
In the first subindex there are extra constrains $0\leq j<i\leq N$ but bah, $i$ can't always reach $N$, the same for the other indexes. With this sign we get that $f\{g\}$ is the first half of $[f,g]$ according to R-W.

\item Try to come up with a sign that makes sense using the Koszul Rule. Problem with this: the degree of $f$ shouldn't appear only applying koszul, but it is in the bracket. Maybe after applying shifts or something that takes into account the arity and degree of $f$, as the $N$ in the formula above.
\end{itemize}
\section{Possible MSE question}

I'm reading [this paper](https://arxiv.org/pdf/hep-th/9409063.pdf) (page 2) and I wanted to check an identity that the author says it's immediate. 

**Definitions**

I'm going to stick to operad notation but I'm interested in the standard example where $O(n)=Hom(V^{\otimes n},V)$ and for $f\in O(n)$ we write $|f|=n-1$. In this context, 

$\gamma(f;1,\dots,1,g_1,1,\dots, 1, g_m,1,\dots, 1)=f(1^{\otimes k_0}\otimes g_1\otimes 1^{\otimes k_1}\otimes\cdots\otimes g_m\otimes 1^{\otimes k_m})$

and we define the brace $f\{g_1,\dots,g_m\}$ as the following sum over all ordering preserving insertions of the $g_i$'s

$\sum (-1)^\epsilon \gamma(f;1,\dots,1,g_1,1,\dots, 1, g_m,1,\dots, 1)$

where $\epsilon=\sum_{p=1}^m|g_p|i_p$, $i_p$ being the number of $1$'s in front of $g_p$.

**Problem**

So I want to check that equation (2) in the paper holds. My problem is only on the signs, so I basically want to know how to simplify an expession of the form

$\sum (-1)^\epsilon\sum (-1)^\delta$

to get only one sum with a sign, say $\mu$, depending on $\delta$ and $\epsilon$. In this case, looking at the lhs of equation (2), we have $x\{x_1,\dots, x_m\}\{y_1,\dots, y_n\}$, so I would compute $x\{x_1,\dots, x_m\}$ first, which by definition is

$\sum (-1)^\epsilon \gamma(x;1,\dots,1,x_1,1,\dots, 1, x_m,1,\dots, 1)$

Then $x\{x_1,\dots, x_m\}\{y_1,\dots, y_n\}$ is, applying linearity, 

$\sum (-1)^\epsilon \sum(-1)^\delta\gamma(\gamma(x;1,\dots,1,x_1,1,\dots, 1, x_m,1,\dots, 1); 1,\dots, 1,y_1,1,\dots,1,y_n,1,\dots,1)$

where $\delta$ is defined analogous to $\epsilon$ but in this case we're counting the number of $1$'s in front on the $y_i$'s (after the inner $\gamma$, so the $1$'s inside that $\gamma$ don't count).

This composition can be rewritten using the associativity property of operads (see for instance *The geometry of iterated loops spaces* by P.May), so that it becomes something of the form

$\gamma(x;\gamma(\cdots),\dots, \gamma(\dots))$

This is really hard to write more clearly, since some $y_i$'s would be in place of some $1$'s (something like $\gamma(1;y_i)=y_i$ and others would be inside some $x_j$ (for example $\gamma(x_l;1,\dots, y_{i_l+1}, 1,\dots, 1,y_{j_l},1\dots,1)$, using the notation of G-V).

So, say we have an operadic composition like that, which is afected by $\delta$ for each insertion of the $y$'s. Notice that before that $\gamma$ there is a number of $1$'s and som $y_{i_l}$. I want to introduce some signs so that it becomes a brace. I'm going to change the notation so that $i_p$ (the number of $1$'s in front of $x_p$) becomes $u^x_p$ and for the $1$'s in front of $y_q$ I'll use $u^y_q$. This way, I have to introduce in front of the operadic composition the sign prescribed by the number of $1$'s in front of each $y$ but inside the composition. So let $i_l+1\leq r\leq j_l$. For $y_r$ we count $u^y_{i_l+1}-u^y_{i_l}-(u^x_l-u^y_{i_l})=u^y_{i_l+1}-u^x_l$ (yes, I could've come up with the final difference without doint the previous steps because I am just substracting the ones in fron of the $x$). So the sign in front of this particular composition (there should be one analogue for each composition inside the big composition and after that the sign for the big composition to be a brace)
$$\sum_{i_l+1\leq r\leq j_l}|y_r|(u^y_r-u^x_l)$$

If I want to substract this sign from $\delta$ I'd better do it by counting the ones left rather than to the sum. For every $y_r$ inside $x_l$ the amount of $1$'s that are left in $\delta$ are those in front of $x_l$, i.e., $u^x_l$. So in $\delta$, for those $y_r$ inside $x_l$ we replace $u^y_r$ by $u^x_l$. Now let's see what happens after doing this for every $x_l$. We have the following sum 

$$\delta_1=\sum_{l=1}^m\sum_{i_l+1\leq r\leq j_l}|y_r|u^x_l$$

But we still have the $y$'s that are outside every $x_l$. Using the notation of G-V, where $j_0=0$ and $i_{m+1}=n$, we have also the sum

$$\delta_2=\sum_{l=1}^{m+1}\sum_{j_{l-1}+1\leq r\leq i_l}|y_r|u^y_r$$

So let us rename $\delta=\delta_1+\delta_2$.

Now for the external brace I need the $1$'s in front of the $y$'s that are outside, but only the $1$'s outside the $x_l$. I would also need the ones in fron of the $x_l$ which are in $\epsilon$, but at this point I'm not sure how to introduce it. I think the sums can be interchanged since, as can be seen in the operadic composition, the position of the $y$'s are independent of the position of the $x$'s. But that was at the beginning, now I've done things that depend on how the $y$'s are inserted in the $x$'s. So maybe I should do that in the opposite order, since the sign of the external brace requires the whole $\epsilon$ and only part of $\delta$, which might be introduced later by distributivity I guess.

IT IS POSSIBLE THAT I END UP GETTING THE BRACES INSIDE THANKS TO THE SUM OUTSIDE, SINCE INSIDE WHAT I HAVE IS OPERADIC COMPOSITION, MAYBE THAT WAY I CAN GET RID OF SOME OF THE SIGNS. I ALSO NEED TO TAKE SOMES SIGNS OUTSIDE TO GET A BIG BRACE OUTSIDE.

TO COUNT THE ONES INSIDE XI IN FRONT OF YJ (ALREADY ASSUMING I'M COUNTING ONE YJ THAT IS INSIDE) I HAVE TO SUBSTRACT TO THE NUMBER OF ARGUMENTS (NOT ONLY ONES) THE NUMBER OF YS IN FRONT OF YJ TOGETHER WITH THE ONES

TO BE ABLE TO WRITE THINGS PROPERLY TRY USING A NOTATION FOR EVERY INPUT INCLUDING THE ONES, SINCE THEIR ARITY MINUS ONE IS ZERO THAT'S NOT GONNA AFFECT THE FINAL RESULT. FOR THIS YOU SHOULD PROBABLY REWRITE THE ORIGINALS SIGNS TOO.

IT WOULDN'T BE SURPRISING THAT I HAD TO TAKE INTO ACCOUNT THE ARITY OF X SINCE DEPENDING ON IT THE NUMBER OF GAPS VARIES, IN PARTICULAR, THE NUMBER OF ONES IN FRONT OF SOME YI INSIDE XJ DEPENDS ON HOW MANY ARE OUTSIDE, WHICH DEPENDS ON THE ARITY OF X. MAYBE THAT'S WHERE THE DEGREE OF F IS GOING TO COME

CONSIDER ALSO THE POSSIBILITY OF DOING EVERYTHING WITHOUT SIGNS (THE ENDOMORPHISM OPERAD USUALLY DOESN'T HAVE SIGNS) TO SEE IF YOU GET EVERYTHING WITHOUT SIGNS, SO THAT YOU COULD GET THE SIGNS BY SHIFTING. FOR THIS, ASK WHAT WAS THE BRACKET ``WITHOUT SIGNS" AND HOW I WOULD GET A SIGN RELATED TO F WHEN IT IS NOT SWAPPED

\section{Sign with consistent explanation}
I WILL PROBABLY CHANGE THE NOTATION TO $\{-\}_n$ WHEN THE ARGUMENTS ARE NOT INSIDE SO THAT THERE IS NO CONFUSION ABOUT HOW MANY ARE WE GOING TO PUT INSIDE. THIS WILL BE NECESSARY LATER

Let's use the same strategy as R-W for the signs of the bracket $[f,g]$. Let $V$ be a graded vector space and $f\in C^{N,i}(V,V)=\hom(C^{\otimes N},V)^i$. Let $S(V)$ the graded vector space with $S(V)^v=V^{v+1}$, and so the suspension map $S:V\to S(V)$ given by the identity map has internal degree $-1$. Define $\sigma(f)$ as the map making the following diagram commutative
\[
\begin{tikzcd}
S(V)^{\otimes N}\arrow[r, "\sigma(f)"]\arrow[d, "(S^{-1})^{\otimes N}"'] & S(V)\\
V^{\otimes N}\arrow[r,"f"] & V\arrow[u, "S"']
\end{tikzcd}
\]

Explicitly, $\sigma(f)=S\circ f\circ (S^{-1})^{\otimes N}\in C^{N,i+N-1}(V,V)$. 

In R-W there is a sign $(-1)^{N+i-1}$ in front of $f$ but it seems to be irrelevant for this purpose. 

Notice that, by the Koszul sign rule $(S^{-1})^{\otimes N}\circ S^{\otimes N}=(-1)^{\sum_{j=1}^{N-1} j}1=(-1)^{\frac{N(N-1)}{2}}1=(-1)^{\binom{N}{2}}Id$, so $(S^{-1})^{\otimes N}= (-1)^{\binom{N}{2}}(S^{\otimes N})^{-1}$. For this reason, given $F\in C^{m,j}(S(V),S(V))$, we have
\[
\sigma^{-1}(F)=(-1)^{\binom{m}{2}}S^{-1}\circ F\circ S^{\otimes m}\in C^{m,j-m+1}(V,V).
\]

For $g_j\in C^{a_j,q_j}(V,V)$, let $$f[g_1,\dots, g_n]=\sum_{k_0+\cdots+k_n=N-n}f(1^{\otimes k_0}\otimes g_1\otimes 1^{\otimes k_1}\otimes\cdots\otimes g_n\otimes 1^{\otimes k_n})\in C^{N-n+\sum a_j, i+\sum q_j}(V,V).$$

We define $f\{g_1,\dots, g_n\}=\sigma^{-1}(\sigma(f)[\sigma(g_1),\dots, \sigma(g_n)])\in C^{N-n+\sum a_j, i+N-1+\sum (q_j+a_j-1)}(V,V).$

This is the same as $f[g_1,\dots, g_n]$ up to sign, so let us compute the sign.
\[
\sigma^{-1}(\sigma(f)[\sigma(g_1),\dots, \sigma(g_n)])=(-1)^{\binom{N-n+\sum a_j}{2}}S^{-1}\circ (\sigma(f)(1^{\otimes k_0}\otimes \sigma(g_1)\otimes 1^{\otimes k_1}\otimes\cdots\otimes \sigma(g_n)\otimes 1^{\otimes k_n}))\circ S^{\otimes N-n+\sum a_j}
\]
\[
=(-1)^{\binom{N-n+\sum a_j}{2}}S^{-1}\circ S\circ f\circ (S^{-1})^{\otimes N}\circ (1^{\otimes k_0}\otimes (S\circ g_1\circ (S^{-1})^{\otimes a_1})\otimes 1^{\otimes k_1}\otimes\cdots\otimes (S\circ g_n\circ (S^{-1})^{\otimes a_n})\otimes 1^{\otimes k_n}))\circ S^{\otimes N-n+\sum a_j}
\]
\begin{align*}
&=(-1)^{\binom{N-n+\sum a_j}{2}}f\circ ((S^{-1})^{k_0}\otimes  S^{-1}\otimes\cdots \otimes  S^{-1}\otimes  (S^{-1})^{k_n})\\ &\circ(1^{\otimes k_0}\otimes (S\circ g_1\circ (S^{-1})^{\otimes a_1})\otimes\cdots\otimes (S\circ g_n\circ (S^{-1})^{\otimes a_n})\otimes 1^{\otimes k_n}))\circ S^{\otimes N-n+\sum a_j}
\end{align*}




Now we move each $1^{\otimes k_{j-1}}\otimes S\circ g_j\circ (S^{-1})^{a_j}$ to apply $(S^{-1})^{k_{j-1}}\otimes S^{-1}$ to it. Doing this to all of them produces a sign

\[
(-1)^{(a_1+q_1-1)(n-1+\sum k_l)+(a_2+q_2-1)(n-2+\sum_2^n k_l)+\cdots+(a_n+q_n-1)k_n}=(-1)^{\sum_{j=1}^n (a_j+q_j-1)(n-j+\sum_j^n k_l)}
\]
 which we call $(-1)^{\varepsilon}$ in the meantime. So now we have, decomposing $S^{\otimes N-n+\sum a_j}$
 
 \[
 (-1)^{\binom{N-n+\sum a_j}{2}+\varepsilon}f\circ((S^{-1})^{k_0}\otimes  g_1\circ (S^{-1})^{\otimes a_1}\otimes\cdots \otimes  g_n\circ (S^{-1})^{\otimes a_n}\otimes  (S^{-1})^{k_n})\circ (S^{\otimes k_0}\otimes S^{\otimes a_1}\otimes\cdots\otimes S^{\otimes a_n}\otimes S^{\otimes k_n})
 \]
 
 Now we turn the tensor of inverses into inverses of tensors by introducing the appropriate signs. More precisely we introduce the sign
 \[
 (-1)^{\delta}=(-1)^{\binom{k_0}{2}+\sum(\binom{a_j}{2}+\binom{k_j}{2})}
 \]
 
  
So we now have
\[
 (-1)^{\binom{N-n+\sum a_j}{2}+\varepsilon+\delta}f\circ((S^{k_0})^{-1}\otimes  g_1\circ (S^{\otimes a_1})^{-1}\otimes\cdots \otimes  g_n\circ (S^{\otimes a_n})^{-1}\otimes  (S^{k_n})^{-1})\circ (S^{\otimes k_0}\otimes S^{\otimes a_1}\otimes\cdots\otimes S^{\otimes a_n}\otimes S^{\otimes k_n})
 \]
 And the next step is moving each component of the last tensor product in front of its inverse. This will produce the sign $(-1)^\gamma$, where
 
 $$\gamma=-k_0\sum_1^n(k_j+a_j+q_j)-a_1(\sum_1^n k_j+\sum_2^n (a_j+q_j))-\cdots -a_nk_n\equiv \sum_{j=0}^nk_j\sum_{l=j+1}^n(k_l+a_l+q_l)+\sum_{j=1}^na_j(\sum_{l=j}^nk_l+\sum_{l=j+1}^n(a_l+q_l))$$
 

 
 So in the end we have
 \[
 f\{g_1,\dots,g_n\}=\sum_{k_0+\cdots+k_n=N-n} (-1)^{\binom{N-n+\sum a_j}{2}+\varepsilon+\delta+\gamma}f(1^{\otimes k_0}\otimes g_1\otimes 1^{\otimes k_1}\otimes\cdots\otimes g_n\otimes 1^{\otimes k_n})
 \]
 I think I'm going to call this sign $(-1)^{\sigma}$ at the moment. We are confident about this sign satisfying the brace algebra relation, but we shoul try to simplify the sign to get rid of the binomial coefficients. An alternative that doesn't produce those coefficients is in the next section. 
 
 \begin{nota}
If anything that goes at the top of a binomial coefficient is less that 2, then the coefficient is 0. In the case of arities or $k_j$ this is because $(S^{-1})^{\otimes 1}=(S^{\otimes 1})^{-1}$ (and if the tensor is taken 0 times then it is the identity and the equality also holds, so there are no signs).
\end{nota}
\section{Simplifying sign}
\begin{itemize}
\item One idea is to try to express the binomials in terms of the number above. I know that $\binom{m}{2}=0\mod 2$ iff $m\equiv 0,1\mod 4$ (so it is 1 otherwise).
\item Another idea that I am more confident about is trying to develop the binomials and do something similar to R-W, where the computation was just cancelling stuff and then notice that $m^2\equiv m\mod 2$. 
\end{itemize}

Notice that $N-n+\sum a_j=\sum k_i +\sum a_j$. In general, consider a finite sum $\sum b_i$. We can simplify $\mod 2$ the binomial coefficients

$$\binom{\sum b_i}{2}+\sum\binom{b_i}{2}$$

in the followin way. Note that all terms will appear squared once in the big binomial coefficient and once in the sum, as so will do the terms themselves, so they will cancel. This will leave the double products which cancel out the 2 in the denominator, so the result in our sign is

$$\sum_{0\leq i<l\leq n}k_ik_l+\sum_{1\leq j<l\leq n}a_ja_l+\sum_{i,j}k_ia_j$$

Recall $\gamma$ in the sign

$$\gamma=-k_0\sum_1^n(k_j+a_j+q_j)-a_1(\sum_1^n k_j+\sum_2^n (a_j+q_j))-\cdots -a_nk_n\equiv \sum_{j=0}^nk_j\sum_{l=j+1}^n(k_l+a_l+q_l)+\sum_{j=1}^na_j(\sum_{l=j}^nk_l+\sum_{l=j+1}^n(a_l+q_l))$$

As we see, all the sums in the previous simplification appear in $\gamma$ so we can cancel them. Let's rewrite $\gamma$ in a way that it becomes more clear:

$$\sum_{0\leq j<l\leq n}k_jk_l+\sum_{0\leq j<l\leq n}k_ja_l+\sum_{0\leq j<l\leq n}k_jq_l+\sum_{1\leq j\leq l\leq n}a_jk_l+\sum_{1\leq j<l\leq n}a_ja_l+\sum_{1\leq j<l\leq n}a_jq_l$$

So after simplifying we have only the term that include the internal degrees, i.e.
$$\sum_{0\leq j<l\leq n}k_jq_l+\sum_{1\leq j<l\leq n}a_jq_l$$

Let's move now to the $\epsilon$ term in the sign. 
$$\varepsilon=\sum_{j=1}^n (a_j+q_j-1)(n-j+\sum_j^n k_l)=\sum_{j=1}^n (a_j+q_j-1)(n-j)+\sum_{1\leq j\leq l\leq n} (a_j+q_j-1)k_l$$

We may stop here, in such a way that the brace sign is 

$$\sigma=\sum_{0\leq j<l\leq n}k_jq_l+\sum_{1\leq j<l\leq n}a_jq_l+\sum_{j=1}^n (a_j+q_j-1)(n-j)+\sum_{1\leq j\leq l\leq n} (a_j+q_j-1)k_l$$


IF I WANT TO TRY TO MAKE IT SIMPLER WORKING ON EPSILON

Let's focus on the second summad. 
$$\sum_{1\leq j\leq l\leq n}(a_j+q_j-1)k_l=\sum_{1\leq j\leq l\leq n}a_jk_l+\sum_{1\leq j\leq l\leq n}q_jk_l+\sum_{1\leq j\leq l\leq n}k_l$$

The second summand can be added to one that we had before and the last summand equals $\sum_{j=1}^njk_j$.

\section{With inverse of the tensor to avoid some binomial coefficients}
Now define $\sigma(f)=S\circ f\circ (S^{\otimes N})^{-1}$. Now the inverse is just $\sigma^{-1}(F)=S^{-1}\circ F\circ S^{\otimes m}$. The process is now very similar to the previous case, but with less signs since there are no binomial coefficientes. This means that
\[
\sigma^{-1}(\sigma(f)[\sigma(g_1),\dots, \sigma(g_n)])=S^{-1}\circ (\sigma(f)(1^{\otimes k_0}\otimes \sigma(g_1)\otimes 1^{\otimes k_1}\otimes\cdots\otimes \sigma(g_n)\otimes 1^{\otimes k_n}))\circ S^{\otimes N-n+\sum a_j}
\]
\[
=S^{-1}\circ S\circ f\circ (S^{\otimes N})^{-1}\circ (1^{\otimes k_0}\otimes (S\circ g_1\circ (S^{\otimes a_1})^{-1})\otimes 1^{\otimes k_1}\otimes\cdots\otimes (S\circ g_n\circ (S^{\otimes a_n})^{-1})\otimes 1^{\otimes k_n}))\circ S^{\otimes N-n+\sum a_j}
\]



Now we can decompose $(S^{\otimes N})^{-1}=(S^{k_0}\otimes  S\otimes\cdots \otimes  S\otimes  S^{k_n})^{-1}$, but to have the inverses inside we will need some signs with binomial coefficients again. More precisely

\[
(S^{\otimes N})^{-1}=(-1)^{\binom{N}{2}}(S^{-1})^{\otimes N}=(-1)^{\binom{N}{2}}(S^{-1})^{\otimes k_0}\otimes S^{-1}\otimes\cdots\otimes S^{-1}\otimes (S^{-1})^{k_n}=
\]
\[
(-1)^{\binom{N}{2}+\sum_0^n\binom{k_j}{2}}(S^{\otimes k_0})^{-1}\otimes S^{-1}\otimes\cdots\otimes S^{-1}\otimes (S^{k_n})^{-1}
\]

Therefore we have
\begin{align*}
(-1)^{\binom{N}{2}+\sum_0^n\binom{k_j}{2}}f&\circ ((S^{\otimes k_0})^{-1}\otimes S^{-1}\otimes\cdots\otimes S^{-1}\otimes (S^{k_n})^{-1})\\ &\circ (1^{\otimes k_0}\otimes (S\circ g_1\circ (S^{\otimes a_1})^{-1})\otimes 1^{\otimes k_1}\otimes\cdots\otimes (S\circ g_n\circ (S^{\otimes a_n})^{-1})\otimes 1^{\otimes k_n}))\circ S^{\otimes N-n+\sum a_j}
\end{align*}

Now the process is identical to the previous convention, so we use the same notation an write
\[
(-1)^{\binom{N}{2}+\sum_0^n\binom{k_j}{2}+\varepsilon}f\circ((S^{-1})^{k_0}\otimes  g_1\circ (S^{-1})^{\otimes a_1}\otimes\cdots \otimes  g_n\circ (S^{-1})^{\otimes a_n}\otimes  (S^{-1})^{k_n})\circ (S^{\otimes k_0}\otimes S^{\otimes a_1}\otimes\cdots\otimes S^{\otimes a_n}\otimes S^{\otimes k_n})
 \]
 And finally
  \[
 f\{g_1,\dots,g_n\}=\sum_{k_0+\cdots+k_n=N-n} (-1)^{\binom{N}{2}+\sum_0^n\binom{k_j}{2}+\varepsilon+\gamma}f(1^{\otimes k_0}\otimes g_1\otimes 1^{\otimes k_1}\otimes\cdots\otimes g_n\otimes 1^{\otimes k_n})
 \]
The difference between this signs and the other is that $\binom{N-n+\sum a_j}{2}$ is replaced by $\binom{N}{2}$ (which is definitely simple) and there is only a part of $\delta$, which is $\sum_0^n\binom{k_j}{2}$, so there are less terms.

The problem with this sign is that for a multiplication $m$ (see later) we have that $m\{m\}=0$ implies $m(1,m)+m(m,1)=0$ and this is not exactly the same as associativity.



%I DON'T GET THE BRACE EQUATION EITHER SINCE THE SECOND TERM DIFFERS BY $(-1)^{a(x)+q(x)}$ WHICH COULD BE A KOSZUL SIGN IF $M$ HAD DEGREE ONE, BUT IT'S NOT THE CASE

%\begin{align*}
%&=f\circ ((S^{-1})^{k_0}\otimes  S^{-1}\otimes\cdots \otimes  S^{-1}\otimes  (S^{-1})^{k_n})\\ &\circ(1^{\otimes k_0}\otimes (S\circ g_1\circ (S^{-1})^{\otimes a_1})\otimes\cdots\otimes (S\circ g_n\circ (S^{-1})^{\otimes a_n})\otimes 1^{\otimes k_n}))\circ S^{\otimes N-n+\sum a_j}
%\end{align*}




\section{Check brace equation}
I'll try to check it first without simplying the sign because some shifts should cancel and the signs appearing all come from the Koszul rule, so I guess the final sign would be that one. An I might not even need to use the sign I got because I will be getting a sign when I do all the process.

Let's start by computing an example where the koszul sign that we need becomes apparent. We know that $m\{m\}=m(1,m)-m(m,1)$, so let us compute $m(1,m)\{x,y,z\}$ and the other term too, which has the same sign. There is only one posibility of insertion that is $m(x,m(y,z))=x(yz)$, which comes with the sign

$$\binom{a(x)+a(y)+a(z)}{2}+a(y)+q(y)-1+\binom{a(x)}{2}+\binom{a(y)}{2}+\binom{a(z)}{2}-a(x)(a(y)+q(y)+a(z)+q(z))-a(y)(a(z)+q(z))\equiv$$
$$a(y)+q(y)-1+a(x)a(y)+a(x)a(z)+a(y)a(z)+a(x)a(y)+a(x)q(y)+a(x)a(z)+a(x)q(z)+a(y)a(z)+a(y)q(z)=$$
$$a(y)+q(y)-1+a(x)q(y)+a(x)q(z)+a(y)q(z)$$

So 
$$m\{m\}\{x,y,z\}=(-1)^{a(y)+q(y)-1+a(x)q(y)+a(x)q(z)+a(y)q(z)}(m(x,m(y,z))-m(m(x,y),z)))$$

Similarly, we can see that the sign produced by $m\{m\{x,y\},z\}$ is given by the exponent $a(y)+q(y)+a(x)q(y)+a(x)q(z)+a(y)q(z)$ which is the same that appears above. And in the case of $m\{x,m\{y,z\}\}$ the exponent is $a(x)+q(x)+a(y)+q(y)+a(x)q(y)+a(x)q(z)+q(y)q(z)$, so the difference is $a(x)+q(x)-1$. 


%THE TERM $M(M(X,Y),Z)$ HAS THE SAME SIGN (INCLUDING THE MINUS SIGN IN FRONT) AS IN THE BRACE $M\{M\{X,Y\},Z\}$ BUT THE OTHER TERM DIFFERS IN THE $-1$ HERE BEING $A(X)+Q(X)$, SO IT'S LIKE THE KOSZUL RULE SHOULD BE APPLIED AS IF THE ARITIES WERE THE SAME AND THE DEGREES WHERE SHIFTED, I.E. SWAPING $M$ AND $X$ YIELD $(A(M)+Q(M)-1)(A(X)+Q(X)-1)\equiv A(X)+Q(X)-1$ (COULD MAKE SENSE WITH THE FACT THAT THE SIGNS COME FROM A SHIFT OF DEGREES AND THE ARITIES PLAY A ROLE IN THAT SHIFT, MORE PRECISELY, THIS IS THE SIGN COMING FROM SWAPING $S\circ m\circ (S^{-1})^{a(m)}$ WITH $S\circ x\circ (S^{-1})^{a(x)}$)

So the actual brace equation for this is 
$$0=m\{m\}\{x,y,z\}=m\{m\{x,y\},z\}+(-1)^{(a(m)+q(m)-1)(a(x)+q(x)-1)}m\{x,m\{y,z\}\}$$

and in general the sign should be that kind of sign, i.e. the total degree of $x$ here is given by $a(x)+q(x)-1$, which is the internal degree of the shift $S\circ x\circ (S^{-1})^{a(x)}$.

Now let's try to prove this in general 
\[
x\{x_1,\dots,x_m\}\{y_1,\dots,y_n\}=\sigma^{-1}(\sigma(x\{x_1,\dots,x_m\})[\sigma(y_1),\dots,\sigma(y_n)])=
\]
\[
\sigma^{-1}(\sigma(\sigma^{-1}(\sigma(x)[\sigma(x_1),\dots, \sigma(x_m)]))[\sigma(y_1),\dots,\sigma(y_n)])=\sigma^{-1}(\sigma(x)[\sigma(x_1),\dots, \sigma(x_m)][\sigma(y_1),\dots,\sigma(y_n)])
\]

TRY TO COMPUTE ONE GENERAL TERM OF THIS SUM AND THE COMPARE WITH THE SAME TERM ON THE RHS OF THE BRACE EQUATION, JUST LIKE YOU DID IN THE PARTICULAR EXAMPLE, MAYBE TRY FIRST A PARTICULAR TERM FOR NOTATIONAL CONVENIENCE TO SEE HOW IT WORKS AND IF NECESSARY THEN TRY TO DO IT FOR THE GENERAL CASE

\section{Lemma 2.2 Derived Conjecture}

We define $x\cdot y=(-1)^{a(x)+q(x)-1}m\{x,y\}$ where $m\in C^{2,0}(V,V)$ such that $m\circ m=m\{m\}=m(1,m)-m(m,1)=0$ ($m$ is a multiplication). %I MIGHT PUT A MINUS SIGN IN FRONT JUST TO GET $M(M,1)-M(1,M)$  INSTEAD BUT WHAT I GOT IS WHAT CONSTANZE HAS and $\sigma$ is the sign corresponding to the definition of the brace. More precisely, we have

%$$\sigma=\binom{a(x)+a(y)}{2}+a(x)+q(x)-1+\binom{a(x)}{2}+\binom{a(y)}{2}+a(x)(a(y)+q(y))$$
%
%SHOULD I REALLY USE THIS SIGN? G-V DON'T USE THE SIGN OF THEIR BRACE, BUT THEIR SIGN DOESN'T GIVE ME ASSOCIATIVITY EITHER WHEN COMPUTING THE TWO PRODUCTS DIRECTLY, AND FOR THIS CASE I'M NOT OBTAINING THE BRACE EQUATION EITHER
%
%ANOTHER POSSIBLE SIGN IS JUST $A(X)+Q(X)-1$, WHICH CORRESPOND TO THE KOSZUL SIGN THAT I USE, OR EVEN WITHOUT THE $-1$ SINCE IT CANCELS. BOTH GIVE ASSOCIATIVITY OF THE PRODUCT BUT LESS OBVIOUSLY BECAUSE ONE HAS TO CHECK THE SIGNS LEFT.
%The binomial coefficients can be simplified mod 2 to $a(x)a(y)$, which cancels mod 2 with one of the terms, leaving
%
%$$\sigma=a(x)+q(x)-1+a(x)q(y)$$

\begin{lemma}
%WRONG, I FORGOT TO APPLY THE KOSZUL RULE IN $m(1,m)-m(m,1)=0$ SO IT'S NOT ASSOCIATIVE, IT IS IF I FORGET ABOUT THE SIGN IN FRONT OF THE PRODUCT 
$x\cdot y$ is associative.
\end{lemma}
\begin{proof}
%THIS IS THE PROOF IF I FINALLY CHOOSE THIS SIGN
%
%Since $x\cdot y$ is by definition $m(x,y)$, the lemma follows from the associativy of $m$ provided that $m\circ m=0$. 
%
%QED
We will use that $m\{x,y\}=(-1)^{a(x)+q(x)-1+a(x)q(y)}m(x,y)$.

Up to sign, $(x\cdot y)\cdot z$ is $m(m(x,y),z)$ and $x\cdot (y\cdot z)$ is $m(x,m(y,z))$. More precisely, we have

\begin{align*}
(x\cdot y)\cdot z=&(-1)^{a(y)+q(y)}m\{m\{x,y\},z\}=\\
&(-1)^{a(x)q(y)+a(x)q(z)+a(y)q(z)}m(m(x,y),z)
\end{align*}
and

\begin{align*}x\cdot (y\cdot z)=(-1)^{a(x)+q(x)+a(y)+q(y)}m\{x,m\{y,z\}\}=\\
(-1)^{a(x)q(y)+a(x)q(z)+a(y)q(z)}m(x,m(y,z))
\end{align*}

%ACTUALLY, WHATEVER THE SIGNS ARE, SINCE THEY ARE CHOSEN TO CANCEL THE SIGN THAT APPEARS WITH THE BRACKETS, IN THE END I WOULD GET $M(X,M(Y,Z))$ ON ONE SIDE AND $M(M(X,Y),Z)$ ON THE OTHER, WHICH ARE EQUAL BY THE PROPERTIES OF $M$.

%The brace equation, using that $m\{m\}=0$ and the degree of $m$ is 0, is exactly
%
%$$0=m\{m\}\{x,y,z\}=m\{m\{x,y\},z\}+m\{x,m\{y,z\}\}$$

%I'M FACING A PROBLEM HERE. THE SIGN IS SO THAT IT CANCELS AND GIVES YOU LITERALLY $M(X,Y)$, BUT WITH THIS BRACE EQUATION YOU DON'T GET THE MINUS SIGN THAT YOU NEED IN ONE TERM



%ACTUALLY I DON'T CARE ABOUT WHAT THIS SIGN IS, THE OTHER TERM WILL HAVE THE SAME SINCE I AM INSERTING 3 ELEMENTS IN THE 3 AVAILABLE SPACES, THIS MEANS THAT THE ASSOCIATIVITY RELATION HOLDS USING THAT, BUT THEN THE BRACE RELATION IS PROBLEMATIC

%WHAT IF THE GOOD KOSZUL SIGN HERE IS THE ANTISYMMETRIC? IF I MULTIPLY BY THE SIGN OF THE PERMUTATION I GET THE MINUS SIGN I NEED

%I THINK I'M GOING TO CHECK WHAT IS THE SIGN THAT I GET IN THIS CASE WHEN TRYING TO EVALUATE THE BRACE EQUATION ON BOTH SIDES




\end{proof}

For $f\in C^{n,i}(V,V)$ and $g\in C^{m,j}(V,V)$ we define the bracket $[f,g]=f\circ g-(-1)^kg\circ f$, where $k=(n+i-1)(m+j-1)$ is the koszul sign of the shift $S$ as in R-W. Then, in a brace algebra with multiplication, define $d(x)=[m,x]=m\circ x-(-1)^{a(x)+q(x)-1}x\circ m$.

\begin{lemma}
$d(d)=0$. 
\end{lemma}
\begin{proof}

$$d(d(x))=d(m\{x\}-(-1)^{a(x)+q(x)-1}x\{m\})=$$ 
$$m\{m\{x\}\}-(-1)^{a(x)+q(x)}m\{x\}\{m\}-(-1)^{a(x)+q(x)-1}(m\{x\{m\}\}-(-1)^{a(x)+q(x)}x\{m\}\{m\})$$




The second summand is 
$m\{x\}\{m\}=(-1)^{a(x)+q(x)-1}m\{m,x\}+m\{x\{m\}\}+m\{x,m\}$. Notice that the second term here cancels the third summand. 


The last summad is
$x\{m\}\{m\}=-x\{m,m\}+x\{m\{m\}\}+x\{m,m\}=0$ since $m\{m\}=0$.

So we are left with

$$m\{m\{x\}\}+(-1)^{a(x)+q(x)-1}m\{x,m\}+m\{m,x\}=m\{m\}\{x\}=0$$

where the first equality is the brace equation CHECK THE BRACE EQUATION FOR THIS PARTICULAR CASE (NOT URGENT, THERE ARE MORE CASES HERE SO IT WOULD BE LONG, JUST DO IT IN THE FUTURE IF YOU CAN'T PROVE IT IN GENERAL)

TRY TO UNDERSTAND THE (GRADED) PRE-LIE STRUCTURE IN THIS CASE \url{https://en.wikipedia.org/wiki/Pre-Lie_algebra}

THE EQUATION ABOVE IS NOT THE SAME AS FOR A PRE-LIE ALGEBRAS (LEFT OR RIGHT \url{http://math.univ-bpclermont.fr/~manchon/biblio/ESI-prelie2009.pdf} from nlab, GRADED PRE-LIE IN GERSTENHABER 1963) SINCE ABOVE $X$ APPEARS ONCE AND ONLY ONCE IN THE FIRST POSITION, AND THIS ONE REMAINS UNMOVED IN THE AXIOM OF PRE-LIE ALGEBRA, SO I DON'T KNOW HOW THIS FOLLOWS FROM THAT


\end{proof}

\begin{lemma}
$d$ and $\cdot$ satisfy the Leibniz rule 
%I STILL HAVE TO FIGURE OUT WHAT SIGN APPEARS IN THE LEIBNIZ RULE, BUT LET'S TRY WITH THE SAME I'VE BEEN USING. NOTICE THAT ARITY(D)=DEGREE(D)=1, SO THE SIGN IS NEGATIVE THIS MEANS THAT I'M GOING TO TRY WITH $d(x\cdot y)=d(x)\cdot y+(-1)^{a(x)+q(x)-1}x\cdot d(y)$
%I GOT THE IDENTITY WITHOUT THE $-1$ IN THE SIGN THERE USING FOR THE PRODUCT THE ALTERNATIVE SIGN. I'LL CHECK WITH THE BRACE SIGN, BUT I'LL STICK TO WHATEVER I GET
\end{lemma}
\begin{proof}
%USING $A(X)+Q(X)-1$ IN THE PRODUCT

$$d(x\cdot y)=d((-1)^{a(x)+q(x)-1}m\{x,y\})=(-1)^{a(x)+q(x)-1}(m\{m\{x,y\}\}-(-1)^{a(x)+q(x)+a(y)+q(y)-1}m\{x,y\}\{m\})$$

$$d(x)\cdot y=(m\{x\}-(-1)^{a(x)+q(x)-1}x\{m\})\cdot y=(-1)^{a(x)+q(x)}(m\{m\{x\},y\}-(-1)^{a(x)+q(x)-1}m\{x\{m\},y\})$$

$$x\cdot d(y)=x\cdot(m\{y\}-(-1)^{a(y)+q(y)-1}y\{m\})=(-1)^{a(x)+q(x)-1}(m\{x,m\{y\}\}-(-1)^{a(y)+q(y)-1}m\{x,y\{m\}\})$$

On the first equation use the brace equation to note that

$$m\{x,y\}\{m\}=m\{x,y\{m\}\}+(-1)^{a(y)+q(y)-1}m\{x\{m\},y\}$$

and also, since $m\{m\}\{x,y\}=0$, the brace equation gives us for the first equation that

$$m\{m\{x,y\}\}=-m\{m\{x\},y\}-(-1)^{a(x)+q(x)-1}m\{x,m\{y\}\}$$

With this in mind, let's compare the first equation with the other two. We have $(-1)^{a(x)+q(x)}m\{m\{x\},y\}$ on the first equation and the same on the second equation. On the first equation we have $-(-1)^{-1}m\{x\{m\},y\}$ and the same on the second equation.

We have $-m\{x,m\{y\}\}$ on the first equation and $(-1)^{a(x)+q(x)-1}m\{x,m\{y\}\}$ on the third, so the difference is $(-1)^{a(x)+q(x)}$. Finally we have $(-1)^{a(y)+q(y)}m\{x,y\{m\}\}$ and on the third equation $(-1)^{a(x)+q(y)+a(y)+q(y)}m\{x,y\{m\}\}$ so again the difference is $(-1)^{a(x)+q(x)}$. So we have the Leibniz rule

$$d(x\cdot y)=d(x)\cdot y+(-1)^{a(x)+q(x)}x\cdot d(y)$$


%WITH THE SIGN OF THE BRACE IT DOESN'T WORK, NEITHER IT DOES DELETING THE $-1$

%USING THE SIGN OF THE BRACE FOR THE PRODUCT
%
%$$d(x\cdot y)=(-1)^{a(x)+q(x)-1+a(x)q(y)}(m\{m\{x,y\}\}-(-1)^{a(x)+q(x)+a(y)+q(y)-1}m\{x,y\}\{m\})$$
%
%$$d(x)\cdot y=(-1)^{a(x)+q(x)+(a(x)+1)q(y)}(m\{m\{x\},y\}-(-1)^{a(x)+q(x)-1}m\{x\{m\},y\})$$
%
%$$x\cdot d(y)=(-1)^{a(x)+q(x)-1 +a(x)q(y)}(m\{x,m\{y\}\}-(-1)^{a(y)+q(y)-1}m\{x,y\{m\}\})$$
%
%On the first equation use the brace equation to note that
%
%$$m\{x,y\}\{m\}=m\{x,y\{m\}\}+(-1)^{a(y)+q(y)-1}m\{x\{m\},y\}$$
%
%and also, since $m\{m\}\{x,y\}=0$, the brace equation gives us for the first equation that
%
%$$m\{m\{x,y\}\}=-m\{m\{x\},y\}-(-1)^{a(x)+q(x)-1}m\{x,m\{y\}\}$$
\end{proof}

FOR LEMMA 2.5 TO MAKE SENSE, I NEED TO SHOW THAT THE CONDITIONS OF DEF2(G-V) TRANSLATED TO MY VERSION MAKE SENSE, SO THAT THEY REALLY IMPLY THAT THE MAP RESPECTS THE PRODUCT AND THE DIFFERENTIAL. I THINK THE CONFUSION OF G-V IS THAT THERE'S THE $d$ IN THE COCHAIN COMPLEX AND THE DIFFERENTIAL WE USE IS $[m+d,]$ SO $D$ MANS THE LAST ONE

%\section{Lemma 2.2 Alternative}



\newpage

\section{Skype}
 \subsection{Notation and sign}
 Same as Lada: $f\in\hom(V^{\otimes N},V)^i$, $g_j\in\hom(V^{\otimes a_i},V)^{q_i}$. In the brace we have a sum of terms like
 
 \[
 (-1)^{\sigma}f(1^{\otimes k_0}\otimes g_1\otimes 1^{\otimes k_1}\otimes\cdots\otimes g_n\otimes 1^{\otimes k_n})
 \]
 
 $$\sigma=\sum_{0\leq j<l\leq n}k_jq_l+\sum_{1\leq j<l\leq n}a_jq_l+\sum_{j=1}^n (a_j+q_j-1)(n-j)+\sum_{1\leq j\leq l\leq n} (a_j+q_j-1)k_l$$
 
 I will also write $a(x)$ and $q(x)$ to specify, respectively, the arity and degree of $x$.
 
 I usually write braces as $x\{-\}$ but I might write also $x\{-\}_n$ or $b_n(x;-)$. The product given by $m$ is $x\cup y=(-1)^{a(x)+q(x)-1}m\{x,y\}$ because that's what made it associative and it's the same sign that appears in the Lie bracket (I tried other signs that didn't work, but still this one gave a weird Leibniz rule, so maybe it's still not the best one).
 
 \subsection{Brace equation}
 
 I wanted to check the brace equation (or brace relation) for $x\{y\}\{z_1,\dots, z_n\}=b_n(b_1(x;y);z_1,\dots, z_n)$ where $n=a(x)+a(y)-1$. First we compute $b_1(x;y)$. For a summand of the form
 
 $$x(1^{k_0}\otimes y\otimes 1^{a(x)-k_0-1})$$
 
 the sign is given by the exponent
 
 $$k_0q(y)+(a(y)+q(y)-1)(a(x)-k_0-1)$$
 
 Finally we compute $b_n(b_1(x;y);z_1,\dots, z_n)$. Taking into account the previous sign, a summand of the form
 
 $$x(z_1\otimes\cdots\otimes z_{k_0}\otimes y(z_{k_0+1}\otimes\cdots\otimes z_{k_0+a(y)})\otimes\cdots z_n)$$
 
 has a sign given by
 
  $$\boxed{k_0q(y)+(a(y)+q(y)-1)(a(x)-k_0-1)+\sum_{1\leq j<l\leq n}a(z_j)q(z_l)+\sum_{j=1}^{a(x)+a(y)-1}(a(z_j)+q(z_j)-1)(a(x)+a(y)-1-j)}$$
 
 
 Next, let's compute the sign of a similar summand on 
 $$x\{z_1,\dots, z_{k_0},y\{z_{k_0+1},\dots, z_{k_0+a(y)}\},\dots, z_n\}$$
 
 First, extract the sign corresponding to $y\{z_{k_0+1},\dots, z_{k_0+a(y)}\}$. This one is given by
 
 $$\sum_{k_0+1\leq j<l\leq k_0+a(y)}a(z_j)q(z_l)+ \sum_{j=k_0+1}^{k_0+a(y)}(a(z_j)+q(z_j)-1)(a(y)+k_0-j)$$
 
 Then, the full sign is given by
  
 \begin{subequations}
\begin{empheq}[box=\widefbox]{align*}
&\sum_{k_0+1\leq j<l\leq k_0+a(y)}a(z_j)q(z_l)+ \sum_{j=k_0+1}^{k_0+a(y)}(a(z_j)+q(z_j)-1)(a(y)+k_0-j)+\\
& \sum_{j<l\leq k_0}a(z_j)q(z_l)+\sum_{j\leq k_0}a(z_j)(q(y)+q(z_{k_0+1})+\cdots+q(z_{k_0+a(y)}))+\sum_{j\leq k_0, l>k_0+a(y)}a(z_j)q(z_l)+\\
&(a(z_{k_0+1})+\cdots+a(z_{k_0+a(y)}))\sum_{l<k_0+a(y)}q(z_l)+\sum_{k_0+a(y)<j<l}a(z_j)q(z_l)+\\
&\sum_{j=1}^{k_0}(a(z_j)+q(z_j)-1)(a(x)+a(y)-1-j)+\sum_{j>k_0+a(y)}(a(z_j)+q(z_j)-1)(a(x)-j-1))+\\%\sum_{j>k_0+a(y)}(a(z_j)+q(z_j)-1)(a(x)+a(y)-(j-a(y)+1))
&(q(y)-1)(a(x)+a(y)-k_0)+(a(x)+a(y)-k_0)\sum_{k_0+1}^{k_0+a(y)}(a(z_j)+q(z_j))
\end{empheq}
\end{subequations}

Now we're going to cancel things that appear on both signs to see what the difference is. 

Note that in the first sign we have the sum $\sum_{1\leq j<l\leq n}a(z_j)q(z_l)$, which cancels several sums in the second sign. So after these cancellations the first sign reduces to 
 $$\boxed{k_0q(y)+(a(y)+q(y)-1)(a(x)-k_0-1)+\sum_{j=1}^{a(x)+a(y)-1}(a(z_j)+q(z_j)-1)(a(x)+a(y)-1-j)}$$
 
 and the second sign to
  \begin{subequations}
\begin{empheq}[box=\widefbox]{align*}
& \sum_{j=k_0+1}^{k_0+a(y)}(a(z_j)+q(z_j)-1)(a(y)+k_0-j)+ q(y)\sum_{j\leq k_0}a(z_j)+\\
&\sum_{j=1}^{k_0}(a(z_j)+q(z_j)-1)(a(x)+a(y)-1-j)+\sum_{j>k_0+a(y)}(a(z_j)+q(z_j)-1)(a(x)-j-1))+\\%\sum_{j>k_0+a(y)}(a(z_j)+q(z_j)-1)(a(x)+a(y)-(j-a(y)+1))
&(q(y)-1)(a(x)+a(y)-k_0)+(a(x)+a(y)-k_0)\sum_{k_0+1}^{k_0+a(y)}(a(z_j)+q(z_j))
\end{empheq}
\end{subequations}



We now see that $q(y)k_0$ appears twice in the first sign so we can just cancel it and rewrite it as
 $$\boxed{(a(y)-1)(a(x)-k_0-1)+q(y)(a(x)-1)+\sum_{j=1}^{a(x)+a(y)-1}(a(z_j)+q(z_j)-1)(a(x)+a(y)-1-j)}$$
 
Now I notice that in the first sign, $q(y)$ is being multiplied by $(a(x)-1)$ while on the second sign it is multiplied by $a(x)+a(y)-k_0+\sum_{j\leq k_0}a(z_j)$. The difference bewteen them is not the Koszul sign. Since the Koszul sign was supposed to be $(a(y)+q(y)-1)\sum_{j=1}^{k_0}(a(z_j)+q(z_j)-1)$, meaning that in particular $q(y)$ is multiplied by $\sum_{j=1}^{k_0}(a(z_j)+q(z_j)-1)$, what I find is that the $q(z_j)$'s are missing and instead I have $a(x)+a(y)$. 

\subsection{Problem with the sign in the product}

Let $\Phi:V\to C^*(V,V)$ the map given by $\Phi(x)=\sum_{n\geq 0}b_n(x;-)$. The conditions in G-V for a brace algebra to be a homotopy G-alegebra should be read as ``$\Phi$ of the product equals the product of $\Phi$'s'' and ``$\Phi$ of the differential equals the differential of $\Phi$''.

Without the signs everything works well. Let's try with the signs. For that, compute $\Phi(x)\cup\Phi(y)$.

\begin{align*}
\Phi(x)\cup\Phi(y)=\sum_{i}b_i(x;-)\cup \sum_{j}b_j(y;-)=\sum_i\sum_j b_i(x;-)\cup b_j(y;-)
\end{align*}

The condition in G-V is stated in terms of each fixed value of $i+j$, so the right hand side of the equation (before evaluation) should be

\begin{align*}
\sum_{n+m}b_n(x;-)\cup b_m(y;-)
\end{align*}
So apparently there is no sign before evaluation. However, let us compute $\Phi(x\cup y)$ in the same way Constanze did in Theorem 2.7.

\begin{align*}
&\Phi(x\cup y)=(-1)^{a(x)+q(x)-1}\Phi(b_2(m;x,y))=(-1)^{\varepsilon}\sum_n b_n(b_2(m;x,y);-)=\\
&(-1)^{\varepsilon}\sum_n\sum_{i+j=n}b_2(b_i(x;-),b_j(y;-))=\sum_n\sum_{i+j=n}(-1)^{a(x)+i}b_i(x;-)\cup b_j(y;-)
\end{align*}
So there is a sign which by the way is not a Koszul sign since we are not evaluating.

\section{More general perspective}
We've been discussing signs from the perspective of the endomorphism operad, but let us figure out the signs in a general brace algebra. This way we might find other signs that suits as well and avoid the problems caused in the end.

Let $|x|$ denote the degree of $x$ that is gonna be used on the sign ($|x|=a(x)+q(x)-1$ so far) and we write $|x||y|$ to mean a product which is not necessarily the product of integers but maybe some kind of dot product as in R-W. Before we studied the brace relation in the case of $m\{m\}\{x,y,z\}$ with the particular brace of the endomorphism operad. Let's now look at this without having any particular brace in mind. We have

$$0=m\{m\}\{x,y,z\}=m\{m\{x,y\},z\}+(-1)^{|x||m|}m\{x,m\{y,z\}\}$$

We want to define a product $x\cdot y=(-1)^{\varepsilon(x,y)}m\{x,y\}$ for which the brace relation above gives us associativity. Associativity means

$$(-1)^{\varepsilon(x,y)+\varepsilon(xy,z)}m\{m\{x,y\},z\}=(-1)^{\varepsilon(x,yz)+\varepsilon(y,z)}m\{x,m\{y,z\}\}$$

By the brace relation this implies $\mod 2$ 

\begin{equation}\label{ass-sing}%\tag{5}
\varepsilon(x,y)+\varepsilon(xy,z)=\varepsilon(x,yz)+\varepsilon(y,z)+|x||m|+1
\end{equation}

%Putting $y=0$ this means that $|x||m|=1\mod 2$. This can be achieve precisely with a dot product like that in R-W, i.e., for $|x|=a(x)+q(x)-1$ and $|y|=a(y)+q(y)-1$ we define $|x||y|=a(x)a(y)+q(x)q(y)+1$. In particular, $|x||m|=2a(x)+0q(x)+1=1$. 
%
%I NOT REALLY SURE HOW THIS FOLLOWS. IF $Y=0$ THEN THE EQUATION BECOMES $0=0$ AND WE CAN PUT WHATEVER SIGNS WE WANT. 

Being $|x||m|=1$, we can simply choose $\varepsilon(x,y)=0$ for all $x,y$ and the brace equation implies associativity. We will test this sign further a bit later. But whatever sign we choose, it's not going to be an analogue to G-V sign for the following reason. In the sign equation given by associativity, since this sign only depends on the first argument, we have

$$\varepsilon(x)+\varepsilon(xy)=\varepsilon(x)+\varepsilon(y)+|x||m|+1$$

I THINK CONSTANZE FORGOT TO TAKE INTO ACCOUNT THE BRACE RELATION HERE, BECAUSE SHE DIDN'T WRITE $|X||M|+1$ actually it is assuming $|x||m|=1$ IN ADDITION I THINK THERE NOT NEED TO BE A 1 FOR THE PRODUCT (AND IN CASE THERE IS, $\varepsilon(1)=0$ NO? IN THAT CASE WE HAVE $\varepsilon(x)=|x||m|+1$ %(ALSO MENTION GETZLER WHERE THE PRODUCT IS DEFINED IN LEMMA 1.5 WITH THE SIGN DEPENDING ON THE FIRST ARGUMENT ONLY) WHICH NOT SO DISCOURAGING EVEN THOUGH IT DOESN'T FEEL SO TRUE

THE BRACE EQUATION IN THE ENDORMORPHISM CASE DOES NOT DEPEND ON THE SIGN OF THE PRODUCT AND THE SIGN CHOSEN THERE WAS MADE SO THAT THE BRACE RELATION HOLDS. BUT IF $|X||M|=1$, THEN IT DOES NOT HOLD. 


DOES IT STILL MAKE SENSE TO USE THE SIGN IN THE LIE BRACKET AS IN THE ENDOMORPHISM? IN THAT PARTICULAR CASE SHOULD BE THE SAME, BUT WITH DOT PRODUCT IS JUST 1. USING THE PREVIOUS SIGN THERE AND THE DOT PRODUCT IN THE BRACE RELATION I DON'T GET $D(D(X))=0$ (BECAUSE THE SIGN MUST BE CONSISTENT WITH THAT IN THE BRACE EQUATION, AND I'VE ALSO FOUND THAT IT IS NECESSARY THAT $|x||m|\equiv |m||m\circ x|+1$ WHICH IS NOT TRUE WITH THE DOT PRODUCT) OR THE LEIBNIZ RULE 

OBVIOUSLY THE PRODDUCT ISSUE IS SOLVED SINCE THERE ARE NO SIGNS INVOLVED

Let us define $d(x)=[m,x]=m\circ x-(-1)^{|x||m|}x\circ m$ and let's see what we need for this to be a diferential, i.e. $d^2=0$. 

\begin{align*}
&d(d(x))=d(m\circ x-(-1)^{|x||m|}x\circ m)=\\
&m\circ (m\circ x)-(-1)^{|x||m|}m\circ(x\circ m)-(-1)^{|m||m\circ x|}(x\circ m)\circ m +(-1)^{|x||m|+|m||m\circ x|}(x\circ m)\circ m
\end{align*}

Using the brace relation and $m\circ m=0$:

\begin{align*}
(m\circ x)\circ m= m\{x,m\}+m\circ(x \circ m)+(-1)^{|m||x|}m\{m,x\}\\
(x\circ m)\circ m=x\{m,m\}+x\circ (m\circ m)-x\{m,m\}=0
\end{align*}
In the last equation we have to assume $|m|\equiv 1$. Then $d(d(x))$ rewrites as
 \[
 m\circ (m\circ x)-(-1)^{|x||m|}m\circ(x\circ m)-(-1)^{|m||m\circ x|}(m\{x,m\}+m\circ(x \circ m)+(-1)^{|m||x|}m\{m,x\})
 \]
 We need $m\circ(x\circ m)$ to cancel, so we impose $|m||x|\equiv |m||m\circ x|+1$. This happens with my sign convention but not with a convention that implies $|m||x|=1$ for all $x$.
 
 Now we use
 
 $$0=m\{m\}\{x\}=m\{m,x\}+m\circ(m\circ x)+(-1)^{|m||x|}m\{x,m\}$$
 To get
 \[
-m\{m,x\}-(-1)^{|m||x|}m\{x,m\}-(-1)^{|m||m\circ x|}(m\{x,m\}+(-1)^{|m||x|}m\{m,x\}=0
 \]
 
 Again, we're assuming  $|m||x|\equiv |m||m\circ x|+1$. WITH THE SIGN CONVENTION OF THE FOLLOWING DOT PRODUCT THIS EQUATION IS TRUE: $((a(x)-1)+q(x))((a(y)-1)+q(y))=(a(x)-1)(a(y)-1)+q(x)q(y)$ SO TRY THIS ONE TOO. THE REASON BEHIND THIS IS THAT THE $-1$ COMES FROM A SHIFT MAP AS WELL AS THE ARITY.
 
Before studying the associativity of the product, note that if we don't put any sign, we depend on $|m||x|=1$, which as we saw caused some problems. But in addition, we will see that the Leibniz rule can't be satisfied in the absence of any sign in front of $m$. First of all, it is natural to assume $|d(x)|=|x|+1$. In the Leibiz rule $d(xy)$ would yield a $-m\{m\{x\},y\}$ coming from the fact that $m\{m\{x,y\}\}=-m\{m\{x\},y\}-(-1)^{|m||x|}m\{x\{m\},y\}$ due to the brace relation. On the other hand, $d(x)y$ produces $m\{m\{x\},y\}$ with positive sign, so whatever sign we include in $xy=(-1)^{\varepsilon(xy)}m\{x,y\}$, it is necessary that $\varepsilon(xy)\equiv\varepsilon(d(x)y)-1$. There are a number of obvious ways to do this is by chosing $\varepsilon(xy)=|x|,|x|+1,|x|+|y|, |x|+|y|+1,\dots$ But using equation \ref{ass-sing} we can discard those like $|x|+|y|$ because we would find that $|m\{x,y\}|$ has to depend on $z$. So we will check $|x|$ and $|x|+1$, being open to other alternatives. With both signs we conclude $|m\{x,y\}|=|m||x|+|y|+1$. Since we want this sign to particularise as the sign in R-W, I would expect $|m||x|=|x|$, so $|m\{x,y\}|=|x|+|y|+1$, but I will use this as little as possible, since with different notions of $|x|$ it could also be the case that $|m||x|=|x|-1$ or anything different and still coincide with the particular numbers in R-W.

ABOUT THE WEIRD LEIBNIZ RULE: IN G-V PAGE 5 BEFORE COROLLARY 5 THERES AN EQUATION THAT BECOMES MY LEIBNIZ RULE WITH $X=M$. I MIGHT TRY TO PROVE IT WITH MY THINGS

WITH $|X|-1$ THE LEIBNIZ RULE IS THE SAME, WRITE IT WITH $|X|$ BUT ALSO TRY TO DO IT WITH A MORE GENERAL SIGN TO SEE IF SOMETHING ELSE CAN BE TRIED

So now let's move to the Leibniz rule. I'm going to check it first for $\varepsilon(xy)=|x|$ (it is analogous for $|x|-1$) and then I will try to do it for a general $\varepsilon(xy)$ satisfying the differential and associativity conditions.

\[
d(xy)=(-1)^{|x|}d(m\{x,y\})=(-1)^{|x|}(m\{m\{x,y\}\}-(-1)^{|m||m\{x,y\}|}m\{x,y\}\{m\})
\]
In the last term we use the breace relation to produce
\[
d(xy)=(-1)^{|x|}(m\{m\{x,y\}\}-(-1)^{|m||m\{x,y\}|}(m\{x,y\{m\}\}+(-1)^{|m||y|}m\{x\{m\},y\}))
\]

Also use the brace relation to rewrite $m\{m\{x,y\}\}$ and produce

\[
d(xy)=(-1)^{|x|}(-m\{m\{x\},y\}-(-1)^{|m||x|}m\{x,m\{y\}\}-(-1)^{|m||m\{x,y\}|}(m\{x,y\{m\}\}+(-1)^{|m||y|}m\{x\{m\},y\}))
\]

Now compute
\[
d(x)y=(-1)^{|x|-1}(m\{m\{x\},y\}-(-1)^{|m||x|}m\{x\{m\},y\})
\]
and
\[
xd(y)=(-1)^{|x|}(m\{x,m\{y\}\}-(-1)^{|m||y|}m\{x,y\{m\}\})
\]

Direct comparison of the terms using that $|m\{x,y\}|=|m||x|+|y|-1$ (also recall that $|m|^2=|m|\mod 2$) by associativity and the necessary fact $|m|=1$ shows that $d(xy)=d(x)y+(-1)^{|x|-1}xd(y)$ (in particular we can't get rid of the minus sign there at least with any sign depending only on $x$, but this is a particular case of the derivation property of the bracket with respect to the product according to G-V page 11).

There's not a lot to change if we use instead some other sign $\varepsilon(xy)$, so let's compare terms. Since $\varepsilon(d(x)y)=\varepsilon(xy)-1$, $m\{m\{x\},y\}$ has the same sign on both sides. For $m\{x\{m\},y\}$ we need 

\[
\varepsilon(xy)+|m||x|=|m||y|+|m||m\{x,y\}|-1+\varepsilon(xy)
\]



As we can see $\varepsilon(xy)$ cancels and we are left with the same as before and the equation holds iff $|m|=1$, which happens in the degrees we've been using. 

Now for $m\{x,m\{y\}\}$ we have on one side $\varepsilon(xy)+|m||x|-1$ and on the other side $\varepsilon(xy)$, so the difference is always $|m||x|-1$ (indeed $|x|$ cause $|m|=1$, whatever sign we use. Similarly, for $m\{x,y\{m\}\}$ we have $\varepsilon(xy)+|m||m\{x,y\}|-1$ on the one side and $\varepsilon(xy)+|m||y|-1$. Now the difference is $|m|(|x|+1)$, but using $|m|=1$ we have the same difference as before.

\section{Generalization to $A_\infty$-algebras}

\subsection{Alternative simpler structure}
I propose as an alternative to the $A_\infty$-structre in the Derived Deligne Conjecture (and also G-V), a simpler family of maps: $M_n(x_1,\dots, x_n)=m_n\{x_1,\dots, x_n\}=b_n(m_n;x_1,\dots, x_n)$. Which is just the last term of the sum taking place in the references.

The proof of Lemma 3.2 in Derived Deligne Conjecture is correct (at least up to signs), so I'm going to prove it just for the simplification (up to signs, as everything in this subsection).

\begin{lemma} The above choice turns $\mathcal{O}$ into an $A_\infty$-algebra.
\end{lemma}
\begin{proof}
We need to show that $M\circ M=0$. 

\[
\underset{0\leq i\leq k}{\sum_{p,q,k=p+q-1}}M_p(x_1,\dots, x_i, M_q(x_{i+1},\dots, x_{i+q}),x_{i+q+1},\dots, x_k)=
\]
\[
\underset{0\leq i\leq k}{\sum_{p,q,k=p+q-1}}b_p(m_p; x_1,\dots, x_i, b_q(m_q;x_{i+1},\dots, x_{i+q}),x_{i+q+1},\dots, x_k)=
\]
\[
\sum_{k,p,q}b_k(b_1(m_p;m_q);x_1,\dots, x_k)=0
\]
because $\sum_{p,q}b_1(m_p;m_q)=0$ since $m\circ m=0$.

IN THIS SIMPLER CASE I THINK IT CAN BE PROVED MORE DIRECTLY SINCE $M\circ M$ iff $\sum M_i\circ M_j=0$ iff $\sum m_i\circ m_j=0$. 
\end{proof}

The following theorem is not fully proved in the general case. This simpler case could serve as a base case, so let's try to prove it.

\begin{theorem}
The morphism $\Phi:\mathcal{O}=\prod_n\mathcal{O}(n)\to C^*(\mathcal{O},\mathcal{O})$ defined by $\Phi(x)=\sum b_n(x;-)$ is a (strict) morphism of $A_\infty$-algebras. 
\end{theorem}

\begin{proof}
Write $j_n$ for the arity (degree? the definition of brace is in graded things, not things with arity, but in the hochschild complex the degree is given by the arity) of $x_n$. 

\[
\Phi(M_n(x_1,\dots, x_n))=\Phi(m_n\{x_1,\dots, x_n\})=\sum_i b_i(b_n(m_n;x_1,\dots, x_n);-)=
\]
\[
\sum_{i=i_1+\cdots+i_n}b_n(m_n;b_{i_1}(x_1;-),\dots, b_{i_n}(x_n;-))
\]
where $i_p\leq j_p$. Note that since the arity of $m_n$ is $n$, there are no terms inserted between the $x_p$'s.

\[
\overline{M}_n(\Phi(x_1),\dots, \Phi(x_n))=\sum_{i_1+\cdots+i_n}\overline{M}_n(b_{i_1}(x_1;-),\dots, b_{i_n}(x_n;-))=\sum_{i_1+\cdots+i_n}b_n(M_n;b_{i_1}(x_1;-),\dots, b_{i_n}(x_n;-))
\] 

Since the arity of $M_n$ is $n$, at least up to sign, this equals
$$\sum_{i_1+\cdots+i_n}b_n(m_n;b_{i_1}(x_1;-),\dots, b_{i_n}(x_n;-))$$

I'LL ASK CONSTANZE TO CHECK THIS. I THINK I MUST (AND CAN) ASSUME THAT THE BRACE IS OF THE KIND OF BRACE IN THE ENDOMORPHISM OPERAD. BUT IF A SIGN COMES ALONG TO DISTINGUISH BETWEEN EVALUATION AND BRACE, THE THEOREM MIGHT NOT BE TRUE ANYMORE. GENERALISING IT TO THE USUAL STRUCTURE WILL BE PROBLEMATIC TOO.
\end{proof}

\subsection{Things with signs}
IN LEMMA 3.2 DON'T FORGET THE SIGN OF THE KOSZUL RULE WHEN EVALUATING, THIS PROBABLY CANCELS THE SIGNS IN THE BRACE RELATION

I'm going to add the signs to the proof of Lemman 2.3 in the original setting (for the simplified version it is analogous).

\begin{lemma}
\end{lemma}
\begin{proof}
In the first line we omit any signs because the maps $M_s$ are not homogeneous.
\[
\underset{0\leq i\leq k}{\sum_{p,q,k=p+q-1}}M_p(x_1,\dots, x_i, M_q(x_{i+1},\dots, x_{i+q}),x_{i+q+1},\dots, x_k)=
\]
\[
\underset{0\leq i\leq k, s\geq p,t\geq q}{\sum_{p,q,k=p+q-1}}(-1)^{|m_t|\sum_{j=1}^i|x_j|}b_p(m_s;x_1,\dots, x_i, b_q(m_t;x_{i+1},\dots, x_{i+q}),x_{i+q+1},\dots, x_k)
\]
The sign above is precisely the koszul sign in the brace relation so this does indeed equal to 

\[
\sum_{k,s,t}b_k(b_1(m_s;m_t);x_1,\dots, x_k)=0.
\]
\end{proof}

IN THE PROOF OF THEOREM 2.7 I GUESS THE SIGN USED FOR THE PRODUCT AND THE DIFFERENTIAL IN THE HOCHSCHILD COMPLEX IS THE ONE COMING FROM THE ENDOMORPHISM CASE, BUT I'LL TRY TO DO IT WITHOUT ASSUMING ANY PARTICULAR VALUE, PROBABLY I SHOULD ALSO CHECK WHAT SIGNS I NEED IN THE SAME WAY I DID WITH M IN ORDER TO GET A DGA IN C(A,A)
\end{document}
